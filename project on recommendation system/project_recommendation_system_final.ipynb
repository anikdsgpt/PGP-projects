{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement - \n",
    "Build your own recommendation system for products on an e-commerce website like Amazon.com.\n",
    "Online E-commerce websites like Amazon, Filpkart uses different recommendation models to provide different suggestions to different users. \n",
    "Amazon currently uses item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real time. This type of filtering matches each of the user's purchased and rated items to similar items, then combines those similar items into a recommendation list for the user.\n",
    "In this project we are going to build recommendation model for the electronics products of Amazon. \n",
    "The dataset here is taken from the below website. \n",
    "Source - Amazon Reviews data (http://jmcauley.ucsd.edu/data/amazon/)  The repository has several datasets. For this case study, we are using the Electronics dataset.\n",
    "\n",
    "Dataset columns - first three columns are userId, productId, and ratings and the fourth column is timestamp. You can discard the timestamp column as in this case you may not need to use it.\n",
    "\n",
    "Please do the analysis based on steps( 1 to 8) as given below - \n",
    "Steps -\n",
    "1.\tRead and explore the given dataset.  ( Rename column/add headers, plot histograms, find data characteristics)\n",
    "2.\tTake a subset of the dataset to make it less sparse/ denser. ( For example, keep the users only who has given 50 or more number of ratings )\n",
    "3.\tSplit the data randomly into train and test dataset. ( For example, split it in 70/30 ratio)\n",
    "4.\tBuild Popularity Recommender model.\n",
    "5.\tBuild Collaborative Filtering model.\n",
    "6.\tEvaluate both the models. ( Once the model is trained on the training data, it can be used to compute the error (RMSE) on predictions made on the test data.)\n",
    "7.\tGet top - K ( K = 5) recommendations. Since our goal is to recommend new products to each user based on his/her habits, we will recommend 5 new products.\n",
    "8.\tSummarise your insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.externals import joblib\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings;warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the raw dataset\n",
    "df = pd.read_csv('ratings_Electronics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKM1MP6P0OYPR</th>\n",
       "      <th>0132793040</th>\n",
       "      <th>5.0</th>\n",
       "      <th>1365811200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1367193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1374451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1QGNMC6O1VW39</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1397433600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AKM1MP6P0OYPR  0132793040  5.0  1365811200\n",
       "0  A2CX7LUOHB2NDG  0321732944  5.0  1341100800\n",
       "1  A2NWSAGRHCP8N5  0439886341  1.0  1367193600\n",
       "2  A2WNBOD3WNDNKT  0439886341  3.0  1374451200\n",
       "3  A1GI0U4ZRJA8WN  0439886341  1.0  1334707200\n",
       "4  A1QGNMC6O1VW39  0511189877  5.0  1397433600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking inside the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7824481, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing a list of column headers\n",
    "column_header = ['userId','productId','ratings','timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column headers in the dataframe\n",
    "df = pd.read_csv('ratings_Electronics.csv',header=None,names=column_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKM1MP6P0OYPR</td>\n",
       "      <td>0132793040</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1365811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1367193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1374451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334707200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId   productId  ratings   timestamp\n",
       "0   AKM1MP6P0OYPR  0132793040      5.0  1365811200\n",
       "1  A2CX7LUOHB2NDG  0321732944      5.0  1341100800\n",
       "2  A2NWSAGRHCP8N5  0439886341      1.0  1367193600\n",
       "3  A2WNBOD3WNDNKT  0439886341      3.0  1374451200\n",
       "4  A1GI0U4ZRJA8WN  0439886341      1.0  1334707200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking into the dataset for the headers\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our analysis dataset, 'timestamp' column is less important hence dropping the column\n",
    "df.drop('timestamp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7824482 entries, 0 to 7824481\n",
      "Data columns (total 3 columns):\n",
      "userId       object\n",
      "productId    object\n",
      "ratings      float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 179.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId        object\n",
       "productId     object\n",
       "ratings      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       0\n",
       "productId    0\n",
       "ratings      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cheching for any null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In popularity based model or in collaborative filtering we consider those users who gave more ratings as we can't say a \n",
    "# product is popular based on one user's rating and also to avoid huge dataset it is essential that we eliminate \n",
    "# users who gave very less number of ratings\n",
    "# In this dataset we filter out users who gave less than 50 ratings\n",
    "# Taking a subset of the dataset , considering those records where count of userID is more than 50\n",
    "counts = df['userId'].value_counts()\n",
    "df_final = df[df['userId'].isin(counts[counts>=50].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125871, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final is the subset of the dataset df where the we have 125871 records compared to 7824481 records which we have earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0132793040</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0321732944</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439886341</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0511189877</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0528881469</th>\n",
       "      <td>2.851852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ratings\n",
       "productId           \n",
       "0132793040  5.000000\n",
       "0321732944  5.000000\n",
       "0439886341  1.666667\n",
       "0511189877  4.500000\n",
       "0528881469  2.851852"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now plotting histograms\n",
    "ratings_hist = pd.DataFrame(df.groupby('productId')['ratings'].mean())\n",
    "ratings_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>number_of_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0132793040</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0321732944</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439886341</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0511189877</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0528881469</th>\n",
       "      <td>2.851852</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ratings  number_of_ratings\n",
       "productId                              \n",
       "0132793040  5.000000                  1\n",
       "0321732944  5.000000                  1\n",
       "0439886341  1.666667                  3\n",
       "0511189877  4.500000                  6\n",
       "0528881469  2.851852                 27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_hist['number_of_ratings'] = df.groupby('productId')['ratings'].count()\n",
    "ratings_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fbf767db38>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_hist['ratings'].hist(bins=50,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the ratings are between 4.0 and 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fb8b67e390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_hist['number_of_ratings'].hist(bins =30,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x1fb8b65ccc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x='ratings', y='number_of_ratings', data=ratings_hist,height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "A5JLAU2ARJ0BO     520\n",
       "ADLVFFE4VBT8      501\n",
       "A3OXHLG6DIBRW8    498\n",
       "A6FIAB28IS79      431\n",
       "A680RUE1FDO8B     406\n",
       "A1ODOGXEYECQQ8    380\n",
       "A36K2N527TXXJN    314\n",
       "A2AY4YUOX2N1BQ    311\n",
       "AWPODHOB4GFWL     308\n",
       "A25C2M3QF9G7OQ    296\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us look into the top 10 users who gave highest number of ratings\n",
    "df_final.groupby('userId').size().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>0594481813</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>0970407998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>0970407998</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId   productId  ratings\n",
       "94   A3BY5KCNQZXV5U  0594451647      5.0\n",
       "118   AT09WGFUM934H  0594481813      3.0\n",
       "177  A32HSNCNPRUMTR  0970407998      1.0\n",
       "178  A17HMM1M7T9PJ1  0970407998      4.0\n",
       "492  A3CLWR1UUZT6TG  0972683275      5.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6595853</th>\n",
       "      <td>A2BYV7S1QP2YIG</td>\n",
       "      <td>B009EAHVTA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738241</th>\n",
       "      <td>AB094YABX21WQ</td>\n",
       "      <td>B0056XCEAA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175596</th>\n",
       "      <td>A3D0UM4ZD2CMAW</td>\n",
       "      <td>B004I763AW</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753016</th>\n",
       "      <td>AATWFX0ZZSE6C</td>\n",
       "      <td>B0040NPHMO</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734767</th>\n",
       "      <td>A1NNMOD9H36Q8E</td>\n",
       "      <td>B0015VW3BM</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userId   productId  ratings\n",
       "6595853  A2BYV7S1QP2YIG  B009EAHVTA      5.0\n",
       "4738241   AB094YABX21WQ  B0056XCEAA      1.0\n",
       "4175596  A3D0UM4ZD2CMAW  B004I763AW      5.0\n",
       "3753016   AATWFX0ZZSE6C  B0040NPHMO      3.0\n",
       "1734767  A1NNMOD9H36Q8E  B0015VW3BM      4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,test_data = train_test_split(df_final,test_size=0.30,random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a basic Popularity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for Popularity based Recommender System model\n",
    "class popularity_recommender_py():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.popularity_recommendations = None\n",
    "        \n",
    "    #Create the popularity based recommender system model\n",
    "    def create(self, train_data, user_id, item_id):\n",
    "        self.train_data = train_data\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "\n",
    "        #Get a count of user_ids for each unique song as recommendation score\n",
    "        train_data_grouped = train_data.groupby([self.item_id]).agg({self.user_id: 'count'}).reset_index()\n",
    "        train_data_grouped.rename(columns = {'userId': 'score'},inplace=True)\n",
    "    \n",
    "        #Sort the products based upon recommendation score\n",
    "        train_data_sort = train_data_grouped.sort_values(['score', self.item_id], ascending = [0,1])\n",
    "    \n",
    "        #Generate a recommendation rank based upon score\n",
    "        train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')\n",
    "        \n",
    "        #Get the top 10 recommendations\n",
    "        self.popularity_recommendations = train_data_sort.head(10)\n",
    "\n",
    "    #Use the popularity based recommender system model to\n",
    "    #make recommendations\n",
    "    def recommend(self, user_id):    \n",
    "        user_recommendations = self.popularity_recommendations\n",
    "        \n",
    "        #Add user_id column for which the recommendations are being generated\n",
    "        user_recommendations['userId'] = user_id\n",
    "    \n",
    "        #Bring user_id column to the front\n",
    "        cols = user_recommendations.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        user_recommendations = user_recommendations[cols]\n",
    "        \n",
    "        return user_recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_grouped = df_final.groupby(['productId']).agg({'ratings' : 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum = df_final_grouped['ratings'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125871\n"
     ]
    }
   ],
   "source": [
    "print(grouped_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_grouped['percentage'] = df_final_grouped['ratings'].div(grouped_sum)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39003</th>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>206</td>\n",
       "      <td>0.163660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24827</th>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>184</td>\n",
       "      <td>0.146181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11078</th>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>167</td>\n",
       "      <td>0.132676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38250</th>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>164</td>\n",
       "      <td>0.130292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38615</th>\n",
       "      <td>B00829TIEK</td>\n",
       "      <td>149</td>\n",
       "      <td>0.118375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        productId  ratings  percentage\n",
       "39003  B0088CJT4U      206    0.163660\n",
       "24827  B003ES5ZUU      184    0.146181\n",
       "11078  B000N99BBC      167    0.132676\n",
       "38250  B007WTAJTO      164    0.130292\n",
       "38615  B00829TIEK      149    0.118375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_grouped.sort_values(['ratings', 'productId'], ascending = [0,1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = df_final['userId'].unique()\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48190"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = df_final['productId'].unique()\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_final, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = popularity_recommender_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.create(train_data, 'userId', 'productId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = users[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting top five recommendations for user A3BY5KCNQZXV5U : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30847</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>122</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId   productId  score  Rank\n",
       "30847  A3BY5KCNQZXV5U  B0088CJT4U    133   1.0\n",
       "30287  A3BY5KCNQZXV5U  B007WTAJTO    124   2.0\n",
       "19647  A3BY5KCNQZXV5U  B003ES5ZUU    122   3.0\n",
       "8752   A3BY5KCNQZXV5U  B000N99BBC    114   4.0\n",
       "30555  A3BY5KCNQZXV5U  B00829THK0     97   5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Predicting top five recommendations for user AT09WGFUM934H : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30847</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>122</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId   productId  score  Rank\n",
       "30847  AT09WGFUM934H  B0088CJT4U    133   1.0\n",
       "30287  AT09WGFUM934H  B007WTAJTO    124   2.0\n",
       "19647  AT09WGFUM934H  B003ES5ZUU    122   3.0\n",
       "8752   AT09WGFUM934H  B000N99BBC    114   4.0\n",
       "30555  AT09WGFUM934H  B00829THK0     97   5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Predicting top five recommendations for user A32HSNCNPRUMTR : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30847</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>122</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId   productId  score  Rank\n",
       "30847  A32HSNCNPRUMTR  B0088CJT4U    133   1.0\n",
       "30287  A32HSNCNPRUMTR  B007WTAJTO    124   2.0\n",
       "19647  A32HSNCNPRUMTR  B003ES5ZUU    122   3.0\n",
       "8752   A32HSNCNPRUMTR  B000N99BBC    114   4.0\n",
       "30555  A32HSNCNPRUMTR  B00829THK0     97   5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Predicting top five recommendations for user A17HMM1M7T9PJ1 : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30847</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>122</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId   productId  score  Rank\n",
       "30847  A17HMM1M7T9PJ1  B0088CJT4U    133   1.0\n",
       "30287  A17HMM1M7T9PJ1  B007WTAJTO    124   2.0\n",
       "19647  A17HMM1M7T9PJ1  B003ES5ZUU    122   3.0\n",
       "8752   A17HMM1M7T9PJ1  B000N99BBC    114   4.0\n",
       "30555  A17HMM1M7T9PJ1  B00829THK0     97   5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Predicting top five recommendations for user A3CLWR1UUZT6TG : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30847</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>122</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId   productId  score  Rank\n",
       "30847  A3CLWR1UUZT6TG  B0088CJT4U    133   1.0\n",
       "30287  A3CLWR1UUZT6TG  B007WTAJTO    124   2.0\n",
       "19647  A3CLWR1UUZT6TG  B003ES5ZUU    122   3.0\n",
       "8752   A3CLWR1UUZT6TG  B000N99BBC    114   4.0\n",
       "30555  A3CLWR1UUZT6TG  B00829THK0     97   5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Predicting recommendations for five users\n",
    "for user in user_id:\n",
    "    print(f\"Predicting top five recommendations for user {user} : \")\n",
    "    inputval = user\n",
    "    pm.recommend(inputval).head(5)\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Collaborative filtering model without using surprise package and using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibcf = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>0594481813</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>0970407998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>0970407998</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId   productId  ratings\n",
       "94   A3BY5KCNQZXV5U  0594451647      5.0\n",
       "118   AT09WGFUM934H  0594481813      3.0\n",
       "177  A32HSNCNPRUMTR  0970407998      1.0\n",
       "178  A17HMM1M7T9PJ1  0970407998      4.0\n",
       "492  A3CLWR1UUZT6TG  0972683275      5.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ibcf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125871, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ibcf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF, tempDF = train_test_split(df_ibcf, test_size = 0.30, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = tempDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF.rating = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3071497</th>\n",
       "      <td>AWH2AY17ZU7W2</td>\n",
       "      <td>B0035JCI6M</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270452</th>\n",
       "      <td>A2MSBIA18RXYQC</td>\n",
       "      <td>B000P1711K</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506249</th>\n",
       "      <td>A1H98YV5K5BUX0</td>\n",
       "      <td>B000WZ7Y5C</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709306</th>\n",
       "      <td>A2X8KN82L07RSK</td>\n",
       "      <td>B00GO4GMAI</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570183</th>\n",
       "      <td>AU627A4UGIW6V</td>\n",
       "      <td>B002EPF6YO</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userId   productId  ratings\n",
       "3071497   AWH2AY17ZU7W2  B0035JCI6M      3.0\n",
       "1270452  A2MSBIA18RXYQC  B000P1711K      1.0\n",
       "1506249  A1H98YV5K5BUX0  B000WZ7Y5C      5.0\n",
       "7709306  A2X8KN82L07RSK  B00GO4GMAI      5.0\n",
       "2570183   AU627A4UGIW6V  B002EPF6YO      4.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = testDF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3071497</th>\n",
       "      <td>AWH2AY17ZU7W2</td>\n",
       "      <td>B0035JCI6M</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270452</th>\n",
       "      <td>A2MSBIA18RXYQC</td>\n",
       "      <td>B000P1711K</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506249</th>\n",
       "      <td>A1H98YV5K5BUX0</td>\n",
       "      <td>B000WZ7Y5C</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709306</th>\n",
       "      <td>A2X8KN82L07RSK</td>\n",
       "      <td>B00GO4GMAI</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570183</th>\n",
       "      <td>AU627A4UGIW6V</td>\n",
       "      <td>B002EPF6YO</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userId   productId  ratings\n",
       "3071497   AWH2AY17ZU7W2  B0035JCI6M      3.0\n",
       "1270452  A2MSBIA18RXYQC  B000P1711K      1.0\n",
       "1506249  A1H98YV5K5BUX0  B000WZ7Y5C      5.0\n",
       "7709306  A2X8KN82L07RSK  B00GO4GMAI      5.0\n",
       "2570183   AU627A4UGIW6V  B002EPF6YO      4.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.concat([trainDF, tempDF]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5993538</td>\n",
       "      <td>ANW6EGY12V5XS</td>\n",
       "      <td>B007ZW43IQ</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4459175</td>\n",
       "      <td>A1QVFHPY8418HC</td>\n",
       "      <td>B004T9Y0MW</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2177400</td>\n",
       "      <td>ALDAF4VVLFRHP</td>\n",
       "      <td>B001NOG2T0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232287</td>\n",
       "      <td>A11YIHB6IW352W</td>\n",
       "      <td>B00007KDVI</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7811983</td>\n",
       "      <td>A3PD8JD9L4WEII</td>\n",
       "      <td>B00JGSWU7S</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          userId   productId  ratings\n",
       "0  5993538   ANW6EGY12V5XS  B007ZW43IQ      4.0\n",
       "1  4459175  A1QVFHPY8418HC  B004T9Y0MW      5.0\n",
       "2  2177400   ALDAF4VVLFRHP  B001NOG2T0      4.0\n",
       "3   232287  A11YIHB6IW352W  B00007KDVI      5.0\n",
       "4  7811983  A3PD8JD9L4WEII  B00JGSWU7S      5.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_df = ratings.pivot(index = 'userId', columns = 'productId', values = 'ratings').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>productId</th>\n",
       "      <th>0594451647</th>\n",
       "      <th>0594481813</th>\n",
       "      <th>0970407998</th>\n",
       "      <th>0972683275</th>\n",
       "      <th>1400501466</th>\n",
       "      <th>1400501520</th>\n",
       "      <th>1400501776</th>\n",
       "      <th>1400532620</th>\n",
       "      <th>1400532655</th>\n",
       "      <th>140053271X</th>\n",
       "      <th>...</th>\n",
       "      <th>B00L5YZCCG</th>\n",
       "      <th>B00L8I6SFY</th>\n",
       "      <th>B00L8QCVL6</th>\n",
       "      <th>B00LA6T0LS</th>\n",
       "      <th>B00LBZ1Z7K</th>\n",
       "      <th>B00LED02VY</th>\n",
       "      <th>B00LGN7Y3G</th>\n",
       "      <th>B00LGQ6HL8</th>\n",
       "      <th>B00LI4ZZO8</th>\n",
       "      <th>B00LKG1MC8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AZBXKUH4AIW3X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZCE11PSTCH1L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZMY6E8B52L2T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZNUHQSHZHSUE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZOK5STV85FBJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "productId      0594451647  0594481813  0970407998  0972683275  1400501466  \\\n",
       "userId                                                                      \n",
       "AZBXKUH4AIW3X         0.0         0.0         0.0         0.0         0.0   \n",
       "AZCE11PSTCH1L         0.0         0.0         0.0         0.0         0.0   \n",
       "AZMY6E8B52L2T         0.0         0.0         0.0         0.0         0.0   \n",
       "AZNUHQSHZHSUE         0.0         0.0         0.0         0.0         0.0   \n",
       "AZOK5STV85FBJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "productId      1400501520  1400501776  1400532620  1400532655  140053271X  \\\n",
       "userId                                                                      \n",
       "AZBXKUH4AIW3X         0.0         0.0         0.0         0.0         0.0   \n",
       "AZCE11PSTCH1L         0.0         0.0         0.0         0.0         0.0   \n",
       "AZMY6E8B52L2T         0.0         0.0         0.0         0.0         0.0   \n",
       "AZNUHQSHZHSUE         0.0         0.0         0.0         0.0         0.0   \n",
       "AZOK5STV85FBJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "productId      ...  B00L5YZCCG  B00L8I6SFY  B00L8QCVL6  B00LA6T0LS  \\\n",
       "userId         ...                                                   \n",
       "AZBXKUH4AIW3X  ...         0.0         0.0         0.0         0.0   \n",
       "AZCE11PSTCH1L  ...         0.0         0.0         0.0         0.0   \n",
       "AZMY6E8B52L2T  ...         0.0         0.0         0.0         0.0   \n",
       "AZNUHQSHZHSUE  ...         0.0         0.0         0.0         0.0   \n",
       "AZOK5STV85FBJ  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "productId      B00LBZ1Z7K  B00LED02VY  B00LGN7Y3G  B00LGQ6HL8  B00LI4ZZO8  \\\n",
       "userId                                                                      \n",
       "AZBXKUH4AIW3X         0.0         0.0         0.0         0.0         0.0   \n",
       "AZCE11PSTCH1L         0.0         0.0         0.0         0.0         0.0   \n",
       "AZMY6E8B52L2T         0.0         0.0         0.0         0.0         0.0   \n",
       "AZNUHQSHZHSUE         0.0         0.0         0.0         0.0         0.0   \n",
       "AZOK5STV85FBJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "productId      B00LKG1MC8  \n",
       "userId                     \n",
       "AZBXKUH4AIW3X         0.0  \n",
       "AZCE11PSTCH1L         0.0  \n",
       "AZMY6E8B52L2T         0.0  \n",
       "AZNUHQSHZHSUE         0.0  \n",
       "AZOK5STV85FBJ         0.0  \n",
       "\n",
       "[5 rows x 48190 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sigma, Vt = svds(R_df, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66.16942358,  66.26045906,  66.5326469 ,  66.73322244,\n",
       "        66.90754989,  67.13857643,  67.52729531,  67.65247592,\n",
       "        67.97832692,  68.1926043 ,  68.431321  ,  68.70278398,\n",
       "        69.17715066,  69.84552982,  69.98332317,  70.19621309,\n",
       "        70.3835867 ,  70.5901626 ,  70.99498997,  71.47879811,\n",
       "        71.60653312,  72.39116477,  72.94294663,  73.4307746 ,\n",
       "        73.49070971,  74.13638941,  74.28327666,  74.47029584,\n",
       "        74.99962629,  75.70165196,  76.31608552,  76.53336712,\n",
       "        77.34117065,  77.76866606,  78.63158661,  79.39214749,\n",
       "        80.2967454 ,  80.95856309,  82.19795763,  83.3788163 ,\n",
       "        87.43474122,  88.68897677,  91.15027972,  92.15989229,\n",
       "        95.03789667,  98.21626326, 100.38232831, 107.7090351 ,\n",
       "       119.69501814, 182.29276718])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66.16942358,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,  66.26045906,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,  66.5326469 , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       ...,\n",
       "       [  0.        ,   0.        ,   0.        , ..., 107.7090351 ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "        119.69501814,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        , 182.29276718]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_predicted_ratings = np.dot(np.dot(U, sigma), Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(all_users_predicted_ratings, columns = R_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>productId</th>\n",
       "      <th>0594451647</th>\n",
       "      <th>0594481813</th>\n",
       "      <th>0970407998</th>\n",
       "      <th>0972683275</th>\n",
       "      <th>1400501466</th>\n",
       "      <th>1400501520</th>\n",
       "      <th>1400501776</th>\n",
       "      <th>1400532620</th>\n",
       "      <th>1400532655</th>\n",
       "      <th>140053271X</th>\n",
       "      <th>...</th>\n",
       "      <th>B00L5YZCCG</th>\n",
       "      <th>B00L8I6SFY</th>\n",
       "      <th>B00L8QCVL6</th>\n",
       "      <th>B00LA6T0LS</th>\n",
       "      <th>B00LBZ1Z7K</th>\n",
       "      <th>B00LED02VY</th>\n",
       "      <th>B00LGN7Y3G</th>\n",
       "      <th>B00LGQ6HL8</th>\n",
       "      <th>B00LI4ZZO8</th>\n",
       "      <th>B00LKG1MC8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>-0.040843</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>0.020659</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.020331</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>-0.061477</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>-0.123433</td>\n",
       "      <td>0.028490</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>-0.174568</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>-0.012997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002286</td>\n",
       "      <td>-0.010898</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>-0.003350</td>\n",
       "      <td>0.063711</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>-0.002433</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>-0.042103</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>-0.024362</td>\n",
       "      <td>-0.014765</td>\n",
       "      <td>0.038570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001655</td>\n",
       "      <td>-0.002675</td>\n",
       "      <td>-0.007355</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>-0.003480</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>-0.006606</td>\n",
       "      <td>-0.002719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>-0.051040</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>-0.054867</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>-0.004996</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>0.083928</td>\n",
       "      <td>-0.112205</td>\n",
       "      <td>0.005964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>-0.005910</td>\n",
       "      <td>-0.014134</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>-0.005391</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>-0.009326</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.048315</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>-0.015263</td>\n",
       "      <td>-0.025996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.002670</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.023761</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>-0.012749</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>-0.020580</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.012770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000311</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>-0.002457</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>-0.007449</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.091134</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.039292</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.003785</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>-0.049641</td>\n",
       "      <td>0.016478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.049992</td>\n",
       "      <td>0.013276</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>-0.038722</td>\n",
       "      <td>-0.013914</td>\n",
       "      <td>-0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.070398</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>-0.015320</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.104971</td>\n",
       "      <td>0.021792</td>\n",
       "      <td>0.122125</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.034022</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.001738</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>-0.002768</td>\n",
       "      <td>0.102026</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>0.043663</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.095637</td>\n",
       "      <td>0.017260</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.064849</td>\n",
       "      <td>-0.064410</td>\n",
       "      <td>0.045463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.013010</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>-0.011782</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>-0.037062</td>\n",
       "      <td>0.031302</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>-0.012566</td>\n",
       "      <td>-0.022399</td>\n",
       "      <td>0.014720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.010045</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>-0.006570</td>\n",
       "      <td>-0.053632</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>-0.005555</td>\n",
       "      <td>-0.030666</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>0.045319</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>-0.044135</td>\n",
       "      <td>-0.017792</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-0.009659</td>\n",
       "      <td>0.112207</td>\n",
       "      <td>-0.029401</td>\n",
       "      <td>-0.051028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>-0.001137</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>0.038256</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>-0.002154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>-0.082278</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>-0.069873</td>\n",
       "      <td>-0.023717</td>\n",
       "      <td>-0.006648</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>-0.125828</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.023731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>-0.007150</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.004811</td>\n",
       "      <td>-0.010059</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001715</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>-0.110638</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.115384</td>\n",
       "      <td>-0.084679</td>\n",
       "      <td>-0.018403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>-0.022663</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.022788</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.034710</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>-0.019662</td>\n",
       "      <td>-0.027720</td>\n",
       "      <td>0.005922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.001748</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.003806</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.016126</td>\n",
       "      <td>-0.003077</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.024569</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>-0.005772</td>\n",
       "      <td>-0.024068</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.055883</td>\n",
       "      <td>0.012702</td>\n",
       "      <td>-0.002092</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.047999</td>\n",
       "      <td>-0.014082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>-0.060012</td>\n",
       "      <td>-0.001850</td>\n",
       "      <td>-0.064100</td>\n",
       "      <td>-0.003730</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>-0.002382</td>\n",
       "      <td>-0.168535</td>\n",
       "      <td>-0.005896</td>\n",
       "      <td>0.007466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.010849</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>-0.003475</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.003655</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.012466</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.004150</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>-0.008322</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>-0.016468</td>\n",
       "      <td>-0.006184</td>\n",
       "      <td>0.007130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>-0.003473</td>\n",
       "      <td>-0.032115</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.051168</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>-0.049782</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>-0.052240</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>-0.020119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.000942</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.004442</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>-0.003686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.028026</td>\n",
       "      <td>-0.027327</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.034551</td>\n",
       "      <td>-0.001801</td>\n",
       "      <td>-0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.114782</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.033221</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>-0.035005</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>-0.095420</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>-0.092096</td>\n",
       "      <td>-0.099807</td>\n",
       "      <td>0.030546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.035782</td>\n",
       "      <td>0.035733</td>\n",
       "      <td>-0.025676</td>\n",
       "      <td>-0.087521</td>\n",
       "      <td>0.105149</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.074291</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.076552</td>\n",
       "      <td>0.016175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>-0.574357</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>-0.092061</td>\n",
       "      <td>0.229725</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>0.503423</td>\n",
       "      <td>-0.127122</td>\n",
       "      <td>0.070185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>-0.024585</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>-0.035082</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>-0.015248</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>-0.011136</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>-0.011966</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>-0.021757</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>-0.033556</td>\n",
       "      <td>-0.002965</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>-0.019037</td>\n",
       "      <td>-0.023649</td>\n",
       "      <td>-0.007424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.010783</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.036073</td>\n",
       "      <td>0.087721</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.086055</td>\n",
       "      <td>0.025108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>-0.397387</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>-0.242535</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>-0.012229</td>\n",
       "      <td>-0.067587</td>\n",
       "      <td>-0.138109</td>\n",
       "      <td>0.129253</td>\n",
       "      <td>-0.062643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>-0.000805</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.014816</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>-0.015917</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>0.010734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002680</td>\n",
       "      <td>-0.010208</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>0.114813</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.012349</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.068882</td>\n",
       "      <td>-0.002738</td>\n",
       "      <td>-0.088450</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>-0.006352</td>\n",
       "      <td>-0.016777</td>\n",
       "      <td>-0.060379</td>\n",
       "      <td>0.024728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.021780</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>-0.048190</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.006634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>-0.005405</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>0.026045</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>-0.003167</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>0.014145</td>\n",
       "      <td>-0.024960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>0.016913</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.027230</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>-0.000190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>-0.013509</td>\n",
       "      <td>-0.032655</td>\n",
       "      <td>-0.007955</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.021462</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.155588</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.019851</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.226846</td>\n",
       "      <td>0.239809</td>\n",
       "      <td>-0.008562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>-0.003048</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.014601</td>\n",
       "      <td>-0.002672</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>-0.040141</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>-0.016785</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>-0.001348</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>-0.101604</td>\n",
       "      <td>0.070434</td>\n",
       "      <td>0.051369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>0.038865</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>0.035694</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>-0.002037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>0.109217</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>-0.014239</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>-0.068890</td>\n",
       "      <td>-0.031235</td>\n",
       "      <td>0.009403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>-0.001719</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>-0.008457</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>-0.005061</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>-0.019054</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>0.018389</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>-0.004276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>-0.051984</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>-0.020611</td>\n",
       "      <td>-0.006501</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>-0.009529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>-0.005778</td>\n",
       "      <td>0.106452</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>-0.003397</td>\n",
       "      <td>0.019256</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>-0.002308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.011815</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.008675</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.010068</td>\n",
       "      <td>0.026222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>0.004433</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>0.053834</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>0.017327</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.036481</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>-0.001154</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>-0.018034</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.035038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.038956</td>\n",
       "      <td>0.029578</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>-0.005961</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>-0.007026</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.057692</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>-0.087784</td>\n",
       "      <td>0.151923</td>\n",
       "      <td>-0.004750</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.148750</td>\n",
       "      <td>-0.068001</td>\n",
       "      <td>-0.028318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>-0.001848</td>\n",
       "      <td>-0.015941</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>-0.126077</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.013755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>-0.013167</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>-0.000879</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.040698</td>\n",
       "      <td>-0.010364</td>\n",
       "      <td>-0.003332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.012949</td>\n",
       "      <td>-0.010515</td>\n",
       "      <td>-0.059973</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>-0.021481</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.033131</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.041012</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.015812</td>\n",
       "      <td>-0.130352</td>\n",
       "      <td>-0.007289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>-0.005090</td>\n",
       "      <td>-0.021104</td>\n",
       "      <td>-0.059035</td>\n",
       "      <td>0.131229</td>\n",
       "      <td>-0.007445</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.289690</td>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.381153</td>\n",
       "      <td>0.074665</td>\n",
       "      <td>0.081235</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>0.623757</td>\n",
       "      <td>0.232262</td>\n",
       "      <td>0.098804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.005848</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.007869</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>-0.008541</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.011017</td>\n",
       "      <td>-0.004166</td>\n",
       "      <td>-0.028001</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>-0.004191</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.047944</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>-0.002551</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>-0.007048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>0.005288</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>-0.001527</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.019506</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.070128</td>\n",
       "      <td>-0.064232</td>\n",
       "      <td>0.004840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>-0.000272</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>-0.055879</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>-0.001269</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>-0.017751</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.016679</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>-0.005912</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>-0.025350</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.094983</td>\n",
       "      <td>-0.003801</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>-0.029311</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>0.008157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>-0.004556</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.008879</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>0.130939</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>0.088393</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>-0.002551</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>-0.033925</td>\n",
       "      <td>-0.012088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>-0.002362</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>-0.018215</td>\n",
       "      <td>-0.001607</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.017000</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>-0.009285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>-0.004729</td>\n",
       "      <td>-0.010599</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>-0.006346</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.012147</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>-0.045895</td>\n",
       "      <td>0.019314</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>-0.061229</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>-0.018458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>0.026654</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.071074</td>\n",
       "      <td>-0.019978</td>\n",
       "      <td>-0.013420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>-0.003294</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>-0.108973</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.013752</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>-0.037539</td>\n",
       "      <td>-0.004680</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>-0.019928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>-0.044696</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.035940</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>0.071724</td>\n",
       "      <td>0.017430</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.052758</td>\n",
       "      <td>0.064170</td>\n",
       "      <td>-0.008820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.024904</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>0.012352</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>0.021273</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.044924</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>-0.105129</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>-0.028850</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.024890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>-0.009187</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>-0.031160</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>0.012194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>-0.002180</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>-0.032059</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>-0.035298</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>-0.023115</td>\n",
       "      <td>-0.032211</td>\n",
       "      <td>-0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>0.013821</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>-0.072233</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>-0.060776</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>0.012861</td>\n",
       "      <td>-0.006706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>0.242378</td>\n",
       "      <td>-0.044660</td>\n",
       "      <td>0.155145</td>\n",
       "      <td>0.062593</td>\n",
       "      <td>0.076326</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.138266</td>\n",
       "      <td>0.442885</td>\n",
       "      <td>-0.042375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>-0.001890</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>-0.011153</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>-0.035989</td>\n",
       "      <td>-0.015108</td>\n",
       "      <td>-0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.059605</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>-0.005455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows  48190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "productId  0594451647  0594481813  0970407998  0972683275  1400501466  \\\n",
       "0            0.005086    0.002178    0.003668   -0.040843    0.009640   \n",
       "1            0.002286   -0.010898   -0.000724    0.130259    0.007506   \n",
       "2           -0.001655   -0.002675   -0.007355    0.007264    0.005152   \n",
       "3            0.001856    0.011019   -0.005910   -0.014134    0.000179   \n",
       "4            0.001115   -0.002670    0.011018    0.014434    0.010319   \n",
       "5            0.000311   -0.000105    0.003827    0.002570    0.005422   \n",
       "6            0.003288    0.007071   -0.002792    0.004335    0.000284   \n",
       "7            0.015611    0.033296   -0.000499   -0.070398    0.009782   \n",
       "8           -0.001738   -0.000504   -0.002768    0.102026    0.005424   \n",
       "9            0.005716    0.012512   -0.000978   -0.013010    0.015682   \n",
       "10          -0.010045   -0.004260   -0.006570   -0.053632   -0.004423   \n",
       "11           0.000809   -0.001137   -0.000606    0.038256    0.010509   \n",
       "12           0.000727    0.004859   -0.007150    0.030858    0.000079   \n",
       "13           0.000817    0.002131    0.003562   -0.022663    0.001200   \n",
       "14           0.002156    0.002866    0.001443   -0.001748    0.003286   \n",
       "15           0.003340    0.012477   -0.005772   -0.024068    0.002266   \n",
       "16           0.002547    0.000638    0.004747    0.004587    0.000718   \n",
       "17           0.000142   -0.000829    0.000376    0.010849   -0.000220   \n",
       "18           0.000045    0.001034    0.001823    0.005915   -0.001005   \n",
       "19           0.001945    0.003967   -0.003473   -0.032115    0.003247   \n",
       "20          -0.000942    0.002407   -0.006059   -0.011823   -0.004981   \n",
       "21           0.005028    0.003703    0.006595    0.114782    0.019880   \n",
       "22           0.035782    0.035733   -0.025676   -0.087521    0.105149   \n",
       "23           0.004680    0.003914    0.007617    0.006865    0.009119   \n",
       "24           0.001476    0.008463   -0.011136   -0.016702    0.001907   \n",
       "25          -0.010783   -0.003708    0.036073    0.087721    0.003455   \n",
       "26           0.000220   -0.000805    0.009238    0.014816    0.001729   \n",
       "27           0.002680   -0.010208    0.015980    0.114813    0.016560   \n",
       "28           0.002856    0.002612    0.016189    0.021780    0.003104   \n",
       "29           0.004959    0.014587   -0.000525   -0.019950    0.005725   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "1510         0.002313    0.000834    0.008510   -0.002050    0.003295   \n",
       "1511         0.001976    0.015198   -0.013509   -0.032655   -0.007955   \n",
       "1512        -0.003048   -0.009681    0.011615    0.016732    0.014601   \n",
       "1513         0.000114   -0.005012   -0.000798    0.038865    0.003566   \n",
       "1514        -0.001719   -0.000526    0.012098   -0.008457    0.004681   \n",
       "1515         0.001290    0.006552    0.000897   -0.051984    0.002849   \n",
       "1516         0.005922    0.003604   -0.005778    0.106452    0.011693   \n",
       "1517         0.004433   -0.001228    0.016751    0.053834    0.017658   \n",
       "1518         0.000366    0.005889    0.005310    0.038956    0.029578   \n",
       "1519         0.004495    0.002117   -0.001651    0.003101    0.001312   \n",
       "1520         0.003898    0.007050    0.004197   -0.013167    0.003983   \n",
       "1521         0.005103    0.012949   -0.010515   -0.059973    0.017301   \n",
       "1522        -0.005090   -0.021104   -0.059035    0.131229   -0.007445   \n",
       "1523         0.000856    0.000302    0.003946   -0.009821    0.001285   \n",
       "1524         0.003126    0.011017   -0.004166   -0.028001    0.001532   \n",
       "1525         0.005288   -0.000146    0.017857   -0.014129    0.007876   \n",
       "1526        -0.000272   -0.001644    0.008692   -0.055879   -0.001415   \n",
       "1527         0.003878    0.007088   -0.002227    0.009042    0.008624   \n",
       "1528         0.001124    0.000925    0.003066   -0.004556    0.003763   \n",
       "1529        -0.002362   -0.002704   -0.002946   -0.018215   -0.001607   \n",
       "1530         0.003715    0.008483   -0.004729   -0.010599    0.003334   \n",
       "1531         0.001032    0.000655    0.000336    0.014832   -0.000421   \n",
       "1532        -0.003294    0.000710    0.018747   -0.108973    0.002087   \n",
       "1533         0.010163    0.021338    0.009992   -0.044696    0.014287   \n",
       "1534         0.002772    0.005771    0.024904    0.008647    0.024080   \n",
       "1535         0.002094    0.005730   -0.004401   -0.009187   -0.001000   \n",
       "1536         0.001344    0.004476   -0.002180    0.009854    0.003112   \n",
       "1537         0.013821    0.011782   -0.072233    0.014284    0.002986   \n",
       "1538         0.002248    0.001607    0.000759    0.009182    0.000816   \n",
       "1539         0.002827    0.002597   -0.004456    0.005795    0.000959   \n",
       "\n",
       "productId  1400501520  1400501776  1400532620  1400532655  140053271X  ...  \\\n",
       "0            0.006808    0.020659    0.000649    0.020331    0.005633  ...   \n",
       "1           -0.003350    0.063711   -0.000674    0.016111   -0.002433  ...   \n",
       "2           -0.003986   -0.003480    0.006961   -0.006606   -0.002719  ...   \n",
       "3            0.001877   -0.005391   -0.001709    0.004968    0.001402  ...   \n",
       "4            0.006002    0.017151    0.003726    0.001404    0.005645  ...   \n",
       "5           -0.002457    0.005309    0.004040   -0.007449   -0.000979  ...   \n",
       "6            0.002187   -0.000012   -0.001257    0.011732    0.001605  ...   \n",
       "7            0.010123   -0.015320    0.000704    0.013545    0.008784  ...   \n",
       "8           -0.001882   -0.011188    0.017720    0.012296   -0.000812  ...   \n",
       "9            0.008826   -0.011782    0.002861    0.002098    0.007464  ...   \n",
       "10          -0.003299    0.036345   -0.005555   -0.030666   -0.003465  ...   \n",
       "11          -0.002247    0.010150    0.004337    0.017317   -0.002154  ...   \n",
       "12          -0.004811   -0.010059   -0.001012   -0.011626   -0.003653  ...   \n",
       "13           0.001502   -0.000229    0.000208    0.006991    0.001311  ...   \n",
       "14           0.002637   -0.002246    0.000604    0.001311    0.002100  ...   \n",
       "15           0.003038   -0.002734    0.001083    0.006358    0.002532  ...   \n",
       "16          -0.002925    0.011214   -0.001364    0.013115   -0.002438  ...   \n",
       "17          -0.000032    0.000984    0.000571    0.009101    0.000020  ...   \n",
       "18          -0.000486   -0.000399    0.000466    0.012466   -0.000341  ...   \n",
       "19          -0.000850    0.001967    0.000013   -0.007590   -0.001143  ...   \n",
       "20          -0.004442   -0.001275    0.000583    0.004537   -0.003686  ...   \n",
       "21           0.003124    0.023368    0.003973    0.033221    0.002883  ...   \n",
       "22           0.015739    0.074291    0.022044    0.076552    0.016175  ...   \n",
       "23           0.003651    0.003432    0.001210    0.003122    0.002983  ...   \n",
       "24           0.000328   -0.011966   -0.000172    0.006216    0.000067  ...   \n",
       "25           0.028722   -0.003325    0.000299    0.086055    0.025108  ...   \n",
       "26          -0.001061    0.004228    0.003405    0.005089   -0.000634  ...   \n",
       "27           0.004451    0.007559    0.006966    0.012349    0.004750  ...   \n",
       "28           0.000865   -0.000880    0.000184    0.000319    0.001027  ...   \n",
       "29           0.004509   -0.005405    0.000285    0.009405    0.003796  ...   \n",
       "...               ...         ...         ...         ...         ...  ...   \n",
       "1510         0.002479    0.009298   -0.000738    0.007754    0.002424  ...   \n",
       "1511        -0.000460   -0.021462   -0.001249    0.002223   -0.000389  ...   \n",
       "1512        -0.002672    0.045299    0.002343    0.025957   -0.002425  ...   \n",
       "1513        -0.002635    0.035694   -0.003740    0.007735   -0.002037  ...   \n",
       "1514         0.000844   -0.007654    0.003301   -0.005061    0.001240  ...   \n",
       "1515         0.003426    0.010887   -0.001292   -0.001247    0.002206  ...   \n",
       "1516        -0.003397    0.019256    0.000352    0.024573   -0.002308  ...   \n",
       "1517         0.008028    0.025047   -0.000486    0.017327    0.007240  ...   \n",
       "1518         0.004201   -0.005961    0.016625   -0.007026    0.004721  ...   \n",
       "1519        -0.000187    0.001906    0.004013    0.007881    0.000067  ...   \n",
       "1520         0.005139    0.002715   -0.000043    0.004737    0.004393  ...   \n",
       "1521         0.003067   -0.021481    0.013576    0.007821    0.002451  ...   \n",
       "1522         0.004261    0.012109    0.005902    0.002392    0.001257  ...   \n",
       "1523         0.001537    0.001950   -0.000227    0.000745    0.001116  ...   \n",
       "1524         0.002229   -0.004191    0.000243    0.006331    0.001816  ...   \n",
       "1525         0.008324    0.007011    0.001568   -0.001527    0.006994  ...   \n",
       "1526        -0.001572    0.008372   -0.002462   -0.001269   -0.001300  ...   \n",
       "1527         0.000381   -0.005912    0.012521    0.021515    0.000374  ...   \n",
       "1528        -0.000047    0.008640    0.000419   -0.008879    0.000362  ...   \n",
       "1529         0.000231    0.014744   -0.001209    0.007266   -0.000210  ...   \n",
       "1530         0.001186   -0.006346   -0.000083    0.000609    0.000940  ...   \n",
       "1531        -0.000213    0.005359   -0.000312    0.004024   -0.000311  ...   \n",
       "1532         0.012171    0.012169   -0.000820   -0.013752    0.009155  ...   \n",
       "1533         0.016708    0.011407    0.002423    0.015164    0.013957  ...   \n",
       "1534         0.012352    0.024636    0.005902    0.021273    0.011362  ...   \n",
       "1535         0.000726   -0.002832   -0.001623    0.003565    0.000561  ...   \n",
       "1536         0.002312    0.001553    0.000308    0.001595    0.001654  ...   \n",
       "1537        -0.007997   -0.060776   -0.011313    0.012861   -0.006706  ...   \n",
       "1538        -0.000335    0.007263   -0.001890    0.003824   -0.000037  ...   \n",
       "1539        -0.000433    0.000766   -0.000125    0.002881   -0.000581  ...   \n",
       "\n",
       "productId  B00L5YZCCG  B00L8I6SFY  B00L8QCVL6  B00LA6T0LS  B00LBZ1Z7K  \\\n",
       "0            0.000238   -0.061477    0.001214   -0.123433    0.028490   \n",
       "1           -0.000038    0.013766    0.001473    0.025588   -0.042103   \n",
       "2           -0.001708   -0.051040    0.000325   -0.054867    0.017870   \n",
       "3            0.000582   -0.009326   -0.000465   -0.048315    0.023302   \n",
       "4            0.000207    0.023761    0.000747   -0.019347   -0.012749   \n",
       "5           -0.000370    0.091134    0.000260    0.039292    0.029386   \n",
       "6            0.000121   -0.058274   -0.000174   -0.049992    0.013276   \n",
       "7            0.002167    0.104971    0.021792    0.122125    0.013596   \n",
       "8           -0.000650    0.043663    0.003391   -0.095637    0.017260   \n",
       "9            0.000518    0.008941    0.002580   -0.037062    0.031302   \n",
       "10          -0.001313    0.045319    0.000631   -0.044135   -0.017792   \n",
       "11           0.001282   -0.082278   -0.003794   -0.069873   -0.023717   \n",
       "12          -0.001715    0.024109   -0.001169   -0.110638    0.020506   \n",
       "13           0.000643   -0.022788   -0.000890   -0.034710    0.001338   \n",
       "14          -0.000057   -0.003806    0.001215   -0.016126   -0.003077   \n",
       "15           0.000153    0.028200    0.012984    0.055883    0.012702   \n",
       "16          -0.000765   -0.060012   -0.001850   -0.064100   -0.003730   \n",
       "17          -0.000048    0.002731   -0.000043    0.010655   -0.003475   \n",
       "18           0.000435   -0.004150   -0.000055   -0.006034   -0.008322   \n",
       "19          -0.000944    0.051168    0.002251    0.013210   -0.049782   \n",
       "20           0.000475    0.004832   -0.000223   -0.028026   -0.027327   \n",
       "21           0.001775   -0.035005    0.005575   -0.095420   -0.024031   \n",
       "22           0.010314   -0.574357    0.024346   -0.092061    0.229725   \n",
       "23           0.000626   -0.024585    0.003856   -0.035082   -0.000758   \n",
       "24           0.000974   -0.021757   -0.000545   -0.033556   -0.002965   \n",
       "25           0.004870   -0.397387    0.051239   -0.242535    0.036050   \n",
       "26           0.001073   -0.015917   -0.000317   -0.009688    0.021884   \n",
       "27          -0.000080   -0.068882   -0.002738   -0.088450    0.018853   \n",
       "28           0.000552    0.040446    0.002017    0.018756    0.001412   \n",
       "29           0.000219    0.034174    0.011969    0.026045    0.024432   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "1510        -0.000272    0.016913    0.000263    0.014463    0.007767   \n",
       "1511        -0.000218    0.155588    0.007621    0.157658    0.019851   \n",
       "1512         0.001886   -0.040141    0.003899   -0.016785    0.003966   \n",
       "1513        -0.001143    0.109217    0.000309    0.058517   -0.014239   \n",
       "1514        -0.000389   -0.001779    0.000935   -0.019054    0.038983   \n",
       "1515         0.001119    0.019544    0.003054    0.061353   -0.020611   \n",
       "1516         0.000880    0.021596    0.001635    0.043595   -0.011815   \n",
       "1517         0.000284    0.048427    0.002502    0.036481   -0.008517   \n",
       "1518        -0.000240   -0.057692    0.002122   -0.087784    0.151923   \n",
       "1519         0.000482   -0.006686   -0.001848   -0.015941    0.009581   \n",
       "1520        -0.000165    0.008115    0.003244    0.003473   -0.000879   \n",
       "1521         0.000834    0.033131    0.001443   -0.041012    0.038161   \n",
       "1522         0.007862    0.289690   -0.009734    0.381153    0.074665   \n",
       "1523        -0.000018   -0.005848    0.000007   -0.007869   -0.004357   \n",
       "1524         0.000535    0.017683    0.011775    0.047944    0.013595   \n",
       "1525         0.000578    0.019506    0.001491   -0.003199   -0.003163   \n",
       "1526         0.000542   -0.017751    0.000641    0.013079   -0.000590   \n",
       "1527         0.000572   -0.025350    0.002278   -0.094983   -0.003801   \n",
       "1528        -0.001544    0.130939   -0.002059    0.088393    0.015767   \n",
       "1529        -0.000036    0.021710   -0.002832    0.000417   -0.017000   \n",
       "1530        -0.000063   -0.012147    0.001014   -0.045895    0.019314   \n",
       "1531        -0.000706    0.026654    0.001426    0.012588    0.004268   \n",
       "1532         0.001868    0.058708   -0.000436    0.004072   -0.037539   \n",
       "1533         0.001876    0.035940    0.020504    0.071724    0.017430   \n",
       "1534         0.002130   -0.044924    0.005465   -0.105129    0.003869   \n",
       "1535         0.000408   -0.031160   -0.002713    0.006911   -0.006653   \n",
       "1536         0.000118   -0.032059    0.000708   -0.035298   -0.000262   \n",
       "1537        -0.003457    0.242378   -0.044660    0.155145    0.062593   \n",
       "1538        -0.001351    0.011663    0.000583   -0.011153    0.002218   \n",
       "1539        -0.000628    0.019144   -0.000843    0.006821    0.005462   \n",
       "\n",
       "productId  B00LED02VY  B00LGN7Y3G  B00LGQ6HL8  B00LI4ZZO8  B00LKG1MC8  \n",
       "0            0.016109    0.002855   -0.174568    0.011367   -0.012997  \n",
       "1            0.004251    0.002177   -0.024362   -0.014765    0.038570  \n",
       "2           -0.004996   -0.002426    0.083928   -0.112205    0.005964  \n",
       "3            0.006790    0.003380    0.005460   -0.015263   -0.025996  \n",
       "4            0.001026    0.001364   -0.020580    0.011828    0.012770  \n",
       "5           -0.000020   -0.003785    0.015064   -0.049641    0.016478  \n",
       "6            0.001588    0.013399   -0.038722   -0.013914   -0.008550  \n",
       "7            0.002983    0.006974    0.034022    0.052811    0.000810  \n",
       "8           -0.005323    0.000063    0.064849   -0.064410    0.045463  \n",
       "9           -0.001298    0.009275   -0.012566   -0.022399    0.014720  \n",
       "10           0.000998   -0.009659    0.112207   -0.029401   -0.051028  \n",
       "11          -0.006648    0.010067   -0.125828    0.036626    0.023731  \n",
       "12           0.022491    0.001593    0.115384   -0.084679   -0.018403  \n",
       "13           0.001902    0.001697   -0.019662   -0.027720    0.005922  \n",
       "14           0.000949    0.000482   -0.024569   -0.007071   -0.002847  \n",
       "15          -0.002092    0.003595    0.085470    0.047999   -0.014082  \n",
       "16           0.001825   -0.002382   -0.168535   -0.005896    0.007466  \n",
       "17           0.000339   -0.000046   -0.003655    0.006312    0.000057  \n",
       "18           0.000562    0.001114   -0.016468   -0.006184    0.007130  \n",
       "19          -0.004830    0.000414   -0.052240   -0.003395   -0.020119  \n",
       "20          -0.000372    0.000063   -0.034551   -0.001801   -0.002063  \n",
       "21           0.001451    0.002317   -0.092096   -0.099807    0.030546  \n",
       "22           0.007454    0.027638    0.503423   -0.127122    0.070185  \n",
       "23           0.002689    0.002714   -0.015248    0.003637    0.003594  \n",
       "24           0.000098    0.008444   -0.019037   -0.023649   -0.007424  \n",
       "25          -0.012229   -0.067587   -0.138109    0.129253   -0.062643  \n",
       "26          -0.000271   -0.000060    0.004116    0.015975    0.010734  \n",
       "27           0.002090   -0.006352   -0.016777   -0.060379    0.024728  \n",
       "28          -0.000686    0.002417   -0.048190   -0.002955    0.006634  \n",
       "29          -0.003167    0.003221   -0.001070    0.014145   -0.024960  \n",
       "...               ...         ...         ...         ...         ...  \n",
       "1510        -0.000401    0.000516   -0.027230   -0.004920   -0.000190  \n",
       "1511         0.019219    0.002168    0.226846    0.239809   -0.008562  \n",
       "1512        -0.001348    0.002945   -0.101604    0.070434    0.051369  \n",
       "1513         0.003833   -0.003482   -0.068890   -0.031235    0.009403  \n",
       "1514        -0.001786   -0.000619    0.018389    0.009368   -0.004276  \n",
       "1515        -0.006501    0.008584    0.003574    0.020135   -0.009529  \n",
       "1516        -0.001844    0.008675    0.007198   -0.010068    0.026222  \n",
       "1517        -0.001154    0.003460   -0.018034    0.000185    0.035038  \n",
       "1518        -0.004750    0.002872    0.148750   -0.068001   -0.028318  \n",
       "1519         0.004160    0.001452   -0.126077    0.007198    0.013755  \n",
       "1520         0.000943    0.003311   -0.040698   -0.010364   -0.003332  \n",
       "1521         0.004479    0.000065   -0.015812   -0.130352   -0.007289  \n",
       "1522         0.081235   -0.007707    0.623757    0.232262    0.098804  \n",
       "1523         0.000437   -0.000819    0.010501   -0.008541    0.001275  \n",
       "1524        -0.002551    0.002321    0.041659    0.043087   -0.007048  \n",
       "1525        -0.000990   -0.000376   -0.070128   -0.064232    0.004840  \n",
       "1526        -0.000106   -0.000990   -0.016679    0.039689    0.005633  \n",
       "1527         0.001584    0.003038   -0.029311   -0.004475    0.008157  \n",
       "1528        -0.001787   -0.002551    0.025170   -0.033925   -0.012088  \n",
       "1529         0.002550   -0.002032    0.003404    0.006752   -0.009285  \n",
       "1530         0.005220    0.003555   -0.061229    0.004871   -0.018458  \n",
       "1531        -0.002260    0.000018   -0.071074   -0.019978   -0.013420  \n",
       "1532        -0.004680    0.002609   -0.028734   -0.008044   -0.019928  \n",
       "1533        -0.002023    0.007208    0.052758    0.064170   -0.008820  \n",
       "1534         0.005393    0.006409   -0.028850    0.003460    0.024890  \n",
       "1535         0.003482    0.004118    0.004914    0.020104    0.012194  \n",
       "1536        -0.000453    0.005973   -0.023115   -0.032211   -0.006800  \n",
       "1537         0.076326    0.019269    0.138266    0.442885   -0.042375  \n",
       "1538         0.000222    0.000442   -0.035989   -0.015108   -0.017988  \n",
       "1539         0.001319    0.001828   -0.059605   -0.010594   -0.005455  \n",
       "\n",
       "[1540 rows x 48190 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(userId,pivot_df,preds_df,num_recommendations):\n",
    "    user_idx = userId-1 # index starts at 0\n",
    "    #Get and sort the user ratings\n",
    "    sorted_user_ratings = pivot_df.iloc[user_idx].sort_values(ascending = False)\n",
    "    #Sorted user ratings\n",
    "    sorted_user_predictions = preds_df.iloc[user_idx].sort_values(ascending = False)\n",
    "    #sorted user predictions\n",
    "    \n",
    "    temp = pd.concat([sorted_user_ratings,sorted_user_predictions],axis=1)\n",
    "    temp.index.name='Recommended Items'\n",
    "    temp.columns = ['user_ratings','user_predictions']\n",
    "    \n",
    "    temp = temp.loc[temp.user_ratings==0]\n",
    "    temp = temp.sort_values('user_predictions',ascending=False)\n",
    "    print(f\"Below are the recommended items for user having user_index as : {userId}\")\n",
    "    print(temp.head(num_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the recommended items for user having user_index as : 1\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B0019EHU8G                  0.0          1.407411\n",
      "B003ES5ZUU                  0.0          1.097482\n",
      "B007OY5V68                  0.0          0.987353\n",
      "B000JMJWV2                  0.0          0.946122\n",
      "B009SYZ8OC                  0.0          0.847875\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 2\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B000N99BBC                  0.0          1.825135\n",
      "B004CLYEDC                  0.0          1.250059\n",
      "B001TH7GSW                  0.0          1.006211\n",
      "B00834SJSK                  0.0          0.947728\n",
      "B00AQRUW4Q                  0.0          0.757301\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 3\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B0088CJT4U                  0.0          1.557864\n",
      "B004T9RR6I                  0.0          1.195031\n",
      "B00BOHNYU6                  0.0          1.032649\n",
      "B00ARB5FLQ                  0.0          0.988891\n",
      "B00829THK0                  0.0          0.912461\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 4\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B001TH7GUU                  0.0          1.062318\n",
      "B000N99BBC                  0.0          0.602050\n",
      "B007WTAJTO                  0.0          0.536436\n",
      "B002V88HFE                  0.0          0.504665\n",
      "B001CIREXA                  0.0          0.496617\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 5\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B0088CJT4U                  0.0          0.745958\n",
      "B003ES5ZUU                  0.0          0.633890\n",
      "B008DWCRQW                  0.0          0.618328\n",
      "B002SQK2F2                  0.0          0.535753\n",
      "B0015DYMVO                  0.0          0.521440\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 6\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B00829TIEK                  0.0          2.045535\n",
      "B008DWCRQW                  0.0          1.136574\n",
      "B00HFRWWAM                  0.0          0.689744\n",
      "B00BOHNYTW                  0.0          0.682880\n",
      "B0019EHU8G                  0.0          0.671300\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 7\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B007WTAJTO                  0.0          0.772433\n",
      "B002V88HFE                  0.0          0.736305\n",
      "B001TH7GUU                  0.0          0.732889\n",
      "B0034CL2ZI                  0.0          0.640834\n",
      "B001E1Y5O6                  0.0          0.578820\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 8\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B002V88HFE                  0.0          1.242437\n",
      "B005HMKKH4                  0.0          1.121752\n",
      "B001TH7GUU                  0.0          1.114841\n",
      "B00DR0PDNE                  0.0          0.974469\n",
      "B0015DYMVO                  0.0          0.922283\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 9\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B00825BZUY                  0.0          1.266061\n",
      "B000N99BBC                  0.0          1.075384\n",
      "B004CLYEFK                  0.0          0.986087\n",
      "B009NHWVIA                  0.0          0.930357\n",
      "B0088CJT4U                  0.0          0.896025\n",
      "----------------------------------------\n",
      "Below are the recommended items for user having user_index as : 10\n",
      "                   user_ratings  user_predictions\n",
      "Recommended Items                                \n",
      "B007WTAJTO                  0.0          1.330201\n",
      "B001TH7GUU                  0.0          1.216939\n",
      "B0019EHU8G                  0.0          0.934725\n",
      "B000VX6XL6                  0.0          0.842173\n",
      "B000QUUFRW                  0.0          0.732741\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "UserIDs = range(1,11)\n",
    "num_recommendations=5\n",
    "for i in UserIDs:\n",
    "    recommend_items(i,R_df,preds_df,num_recommendations)\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48190, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_actual_ratings</th>\n",
       "      <th>Avg_predicted_ratings</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0594451647</th>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0594481813</th>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0970407998</th>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0972683275</th>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400501466</th>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg_actual_ratings  Avg_predicted_ratings  item_index\n",
       "productId                                                        \n",
       "0594451647            0.003247               0.001953           0\n",
       "0594481813            0.001948               0.002875           1\n",
       "0970407998            0.003247               0.003355           2\n",
       "0972683275            0.012338               0.010343           3\n",
       "1400501466            0.012987               0.004871           4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_df = pd.concat([R_df.mean(),preds_df.mean()],axis=1)\n",
    "\n",
    "rmse_df.columns = ['Avg_actual_ratings','Avg_predicted_ratings']\n",
    "# rmse_df.dropna(axis=0,inplace=True)\n",
    "print(rmse_df.shape)\n",
    "rmse_df['item_index'] = np.arange(0,rmse_df.shape[0],1)\n",
    "rmse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE SVD Model = 0.00275\n"
     ]
    }
   ],
   "source": [
    "RMSE = round((((rmse_df.Avg_actual_ratings - rmse_df.Avg_predicted_ratings)**2).mean()**0.5),5)\n",
    "print(f\"RMSE SVD Model = {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE SVD Model = 0.00275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based Collaborative Filtering with KNNWithMeans using surprise package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset,Reader\n",
    "from surprise import KNNWithMeans\n",
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125871, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets exclude movies with very few ratings, say less than 5, this is done to avoid memory error while trying to feed the model\n",
    "product_count = df_final[\"productId\"].value_counts(ascending=False)\n",
    "pop_product = product_count.loc[product_count.values > 15].index\n",
    "len(pop_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27265, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = df_final.loc[df_final.productId.isin(pop_product)]\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(ratings[['userId', 'productId', 'ratings']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x1fb985988d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to train and test\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=.30,random_state=123)\n",
    "\n",
    "# to build on full data\n",
    "#trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use item-based pearson similarity\n",
    "sim_options = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1fb8ba53dd8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9599195493637213"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "# Evalute on test set\n",
    "test_pred = algo.test(testset)\n",
    "\n",
    "# compute RMSE\n",
    "accuracy.rmse(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Algorithm Parameters for KNNWithMeans\n",
    "\n",
    "#We are not getting a good RMSE value hence we need to tune the algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9263875752509039\n",
      "{'sim_options': {'name': 'pearson', 'min_support': 5, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\" , \"pearson\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyper parameters\n",
    "# 'sim_options': {'name': 'pearson', 'min_support': 5, 'user_based': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"min_support\":5,\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1fb8dd68fd0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9220172056096549"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalute on test set\n",
    "test_pred = algo.test(testset)\n",
    "\n",
    "# compute RMSE\n",
    "accuracy.rmse(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After applying the hyper parameters we get a slight decresae in the RMSE value , which means the performance of our model increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='A2W9GX82SLKROQ', iid='B00BWL33H8', r_ui=4.0, est=4.318181818181818, details={'actual_k': 0, 'was_impossible': False})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a particular prediction\n",
    "test_pred[12]\n",
    "\n",
    "# To access a particular value, say estimate simply mention test_pred[12].est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to dataframe\n",
    "test_pred_df = pd.DataFrame(test_pred)\n",
    "test_pred_df[\"was_impossible\"] = [x[\"was_impossible\"] for x in test_pred_df[\"details\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "      <th>was_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1ODOGXEYECQQ8</td>\n",
       "      <td>B00DDK1QUC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.811111</td>\n",
       "      <td>{'actual_k': 1, 'was_impossible': False}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A10Y058K7B96C6</td>\n",
       "      <td>B008OEHV6U</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2NJQF2UI60VGT</td>\n",
       "      <td>B002ZCXJZE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.521739</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11T807LX2EF00</td>\n",
       "      <td>B003CFATT2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2K6CDQ9HZ359G</td>\n",
       "      <td>B004T9RR6I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.969697</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              uid         iid  r_ui       est  \\\n",
       "0  A1ODOGXEYECQQ8  B00DDK1QUC   4.0  3.811111   \n",
       "1  A10Y058K7B96C6  B008OEHV6U   3.0  3.583333   \n",
       "2  A2NJQF2UI60VGT  B002ZCXJZE   5.0  4.521739   \n",
       "3  A11T807LX2EF00  B003CFATT2   5.0  4.833333   \n",
       "4  A2K6CDQ9HZ359G  B004T9RR6I   4.0  3.969697   \n",
       "\n",
       "                                    details  was_impossible  \n",
       "0  {'actual_k': 1, 'was_impossible': False}           False  \n",
       "1  {'actual_k': 0, 'was_impossible': False}           False  \n",
       "2  {'actual_k': 0, 'was_impossible': False}           False  \n",
       "3  {'actual_k': 0, 'was_impossible': False}           False  \n",
       "4  {'actual_k': 0, 'was_impossible': False}           False  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significancce of 'was_impossible' is that True means there are no sufficient data to derive any logic for recommendation and False means that is is possible to recommend value based on data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='A1ODOGXEYECQQ8', iid='B00DDK1QUC', r_ui=None, est=3.811111111111111, details={'actual_k': 1, 'was_impossible': False})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Predictions\n",
    "# Mkae prediction for a single user\n",
    "algo.predict(uid=\"A1ODOGXEYECQQ8\",iid=\"B00DDK1QUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating top n recommendations\n",
    "testset_new = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1427740"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A2UKE7GIVC7XFW', 'B001CCAISE', 4.348860361540477),\n",
       " ('A2UKE7GIVC7XFW', 'B000LRMS66', 4.348860361540477),\n",
       " ('A2UKE7GIVC7XFW', 'B00B4OCWE8', 4.348860361540477),\n",
       " ('A2UKE7GIVC7XFW', 'B000AZ57M6', 4.348860361540477),\n",
       " ('A2UKE7GIVC7XFW', 'B004CLYEH8', 4.348860361540477)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_new[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset_new[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([[x.uid,x.iid,x.est] for x in predictions])\n",
    "predictions_df.columns = [\"userId\",\"productId\",\"est_rating\"]\n",
    "predictions_df.sort_values(by = [\"userId\", \"est_rating\"],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>est_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>AR6APXLK7TJU2</td>\n",
       "      <td>B000IJY8DS</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>AR6APXLK7TJU2</td>\n",
       "      <td>B00D856NOG</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>AR6APXLK7TJU2</td>\n",
       "      <td>B004CLYEFK</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>AR6APXLK7TJU2</td>\n",
       "      <td>B005LDLP8W</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>AR6APXLK7TJU2</td>\n",
       "      <td>B0046TJG1U</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId   productId  est_rating\n",
       "5668  AR6APXLK7TJU2  B000IJY8DS         5.0\n",
       "5769  AR6APXLK7TJU2  B00D856NOG         5.0\n",
       "5806  AR6APXLK7TJU2  B004CLYEFK         5.0\n",
       "5826  AR6APXLK7TJU2  B005LDLP8W         5.0\n",
       "5869  AR6APXLK7TJU2  B0046TJG1U         5.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to recommend top 5 models for all the users\n",
    "top_5_recos = predictions_df.groupby(\"userId\").head(5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            userId   productId  est_rating\n",
      "0    AR6APXLK7TJU2  B000IJY8DS         5.0\n",
      "1    AR6APXLK7TJU2  B00D856NOG         5.0\n",
      "2    AR6APXLK7TJU2  B004CLYEFK         5.0\n",
      "3    AR6APXLK7TJU2  B005LDLP8W         5.0\n",
      "4    AR6APXLK7TJU2  B0046TJG1U         5.0\n",
      "5   A3Q4TYJVAM4IRM  B002V88HFE         5.0\n",
      "6   A3Q4TYJVAM4IRM  B00CD8ADKO         5.0\n",
      "7   A3Q4TYJVAM4IRM  B00834SJNA         5.0\n",
      "8   A3Q4TYJVAM4IRM  B000IJY8DS         5.0\n",
      "9   A3Q4TYJVAM4IRM  B00829THVO         5.0\n",
      "10  A353U0L2HAMSHV  B000IJY8DS         5.0\n",
      "11  A353U0L2HAMSHV  B00D856NOG         5.0\n",
      "12  A353U0L2HAMSHV  B005LDLP8W         5.0\n",
      "13  A353U0L2HAMSHV  B0046TJG1U         5.0\n",
      "14  A353U0L2HAMSHV  B001O4EPHA         5.0\n",
      "15  A2UKE7GIVC7XFW  B004CLYEH8         5.0\n",
      "16  A2UKE7GIVC7XFW  B005DKZTMG         5.0\n",
      "17  A2UKE7GIVC7XFW  B0042FZ50O         5.0\n",
      "18  A2UKE7GIVC7XFW  B000N99BBC         5.0\n",
      "19  A2UKE7GIVC7XFW  B006TF37H8         5.0\n",
      "20  A2TMFC9O3ZCNKE  B000IJY8DS         5.0\n",
      "21  A2TMFC9O3ZCNKE  B00D856NOG         5.0\n",
      "22  A2TMFC9O3ZCNKE  B00829TIA4         5.0\n",
      "23  A2TMFC9O3ZCNKE  B005LDLP8W         5.0\n",
      "24  A2TMFC9O3ZCNKE  B0046TJG1U         5.0\n",
      "25  A2RWHTNM5P3I8Y  B001TOD7ME         5.0\n",
      "26  A2RWHTNM5P3I8Y  B00CD8ADKO         5.0\n",
      "27  A2RWHTNM5P3I8Y  B00GO4GMAI         5.0\n",
      "28  A2RWHTNM5P3I8Y  B00834SJNA         5.0\n",
      "29  A2RWHTNM5P3I8Y  B000N99BBC         5.0\n",
      "30  A2PREU4LOFQRB1  B005DKZTMG         5.0\n",
      "31  A2PREU4LOFQRB1  B000N99BBC         5.0\n",
      "32  A2PREU4LOFQRB1  B000IJY8DS         5.0\n",
      "33  A2PREU4LOFQRB1  B00D856NOG         5.0\n",
      "34  A2PREU4LOFQRB1  B0082E9K7U         5.0\n",
      "35  A2BLFCOPSMBOZ9  B003M8HWDA         5.0\n",
      "36  A2BLFCOPSMBOZ9  B00FR6VL50         5.0\n",
      "37  A2BLFCOPSMBOZ9  B000IJY8DS         5.0\n",
      "38  A2BLFCOPSMBOZ9  B00D856NOG         5.0\n",
      "39  A2BLFCOPSMBOZ9  B009VV56TY         5.0\n",
      "40  A23GFTVIETX7DS  B001TOD7ME         5.0\n",
      "41  A23GFTVIETX7DS  B009HQCARY         5.0\n",
      "42  A23GFTVIETX7DS  B00834SJNA         5.0\n",
      "43  A23GFTVIETX7DS  B000N99BBC         5.0\n",
      "44  A23GFTVIETX7DS  B00CB2F65O         5.0\n",
      "45  A1Q5P5ML3176C0  B000IJY8DS         5.0\n",
      "46  A1Q5P5ML3176C0  B00D856NOG         5.0\n",
      "47  A1Q5P5ML3176C0  B005LDLP8W         5.0\n",
      "48  A1Q5P5ML3176C0  B0046TJG1U         5.0\n",
      "49  A1Q5P5ML3176C0  B001O4EPHA         5.0\n",
      "50  A16RI68PS6T5CA  B000IJY8DS         5.0\n",
      "51  A16RI68PS6T5CA  B00D856NOG         5.0\n",
      "52  A16RI68PS6T5CA  B005LDLP8W         5.0\n",
      "53  A16RI68PS6T5CA  B00G4UQ6U8         5.0\n",
      "54  A16RI68PS6T5CA  B0046TJG1U         5.0\n"
     ]
    }
   ],
   "source": [
    "print(top_5_recos) # Printing top 5 records for all users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD using surprise package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1fb8dd4a3c8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = SVD(n_factors=50,biased=False)\n",
    "svd_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svd_model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3843269427987877"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute RMSE\n",
    "accuracy.rmse(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get large RMSE value showing a poor recommender model hence we tune the model parameters. The reason behind high RMSE is that we biased the dataset earlier reducing lot of records in order to avoid memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8739408494750811\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4, 'biased': True, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.4, 0.6],\n",
    "    \"biased\":[True,False],\n",
    "    \"n_factors\" : [50,100]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1fb985ac710>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model with best hyper parameters\n",
    "svd_model = SVD(n_epochs= 10, lr_all= 0.005, reg_all= 0.4,biased=True,n_factors=50)\n",
    "svd_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3843269427987877"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute RMSE\n",
    "accuracy.rmse(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating top n recommendations\n",
    "testset_new = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svd_model.test(testset_new[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([[x.uid,x.iid,x.est] for x in predictions])\n",
    "predictions_df.columns = [\"userId\",\"productId\",\"est_rating\"]\n",
    "predictions_df.sort_values(by = [\"userId\", \"est_rating\"],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to recommend top 5 models for all the users\n",
    "top_5_recos = predictions_df.groupby(\"userId\").head(5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            userId   productId  est_rating\n",
      "0    AR6APXLK7TJU2  B0052SCU8U    4.719217\n",
      "1    AR6APXLK7TJU2  B001TH7T2U    4.717020\n",
      "2    AR6APXLK7TJU2  B0019EHU8G    4.714220\n",
      "3    AR6APXLK7TJU2  B00BW6KCTU    4.686056\n",
      "4    AR6APXLK7TJU2  B000QUUFRW    4.682801\n",
      "5   A3Q4TYJVAM4IRM  B001TH7T2U    4.688883\n",
      "6   A3Q4TYJVAM4IRM  B0019EHU8G    4.680541\n",
      "7   A3Q4TYJVAM4IRM  B0052SCU8U    4.664654\n",
      "8   A3Q4TYJVAM4IRM  B000QUUFRW    4.640808\n",
      "9   A3Q4TYJVAM4IRM  B000BQ7GW8    4.631778\n",
      "10  A353U0L2HAMSHV  B0052SCU8U    4.660237\n",
      "11  A353U0L2HAMSHV  B001TH7T2U    4.643557\n",
      "12  A353U0L2HAMSHV  B00BW6KCTU    4.615242\n",
      "13  A353U0L2HAMSHV  B0019EHU8G    4.614910\n",
      "14  A353U0L2HAMSHV  B008EQZ25K    4.613012\n",
      "15  A2UKE7GIVC7XFW  B0052SCU8U    4.834653\n",
      "16  A2UKE7GIVC7XFW  B0019EHU8G    4.770515\n",
      "17  A2UKE7GIVC7XFW  B001TH7T2U    4.763837\n",
      "18  A2UKE7GIVC7XFW  B000BQ7GW8    4.755292\n",
      "19  A2UKE7GIVC7XFW  B001TH7GUU    4.751713\n",
      "20  A2TMFC9O3ZCNKE  B0052SCU8U    4.636611\n",
      "21  A2TMFC9O3ZCNKE  B0019EHU8G    4.630634\n",
      "22  A2TMFC9O3ZCNKE  B00017LSPI    4.622476\n",
      "23  A2TMFC9O3ZCNKE  B000QUUFRW    4.616188\n",
      "24  A2TMFC9O3ZCNKE  B001TH7GUU    4.611594\n",
      "25  A2RWHTNM5P3I8Y  B0052SCU8U    4.609024\n",
      "26  A2RWHTNM5P3I8Y  B001TH7T2U    4.587852\n",
      "27  A2RWHTNM5P3I8Y  B001TH7GUU    4.570851\n",
      "28  A2RWHTNM5P3I8Y  B00BQ4F9ZA    4.564454\n",
      "29  A2RWHTNM5P3I8Y  B006W8U2MU    4.564114\n",
      "30  A2PREU4LOFQRB1  B0052SCU8U    4.832957\n",
      "31  A2PREU4LOFQRB1  B000BQ7GW8    4.785527\n",
      "32  A2PREU4LOFQRB1  B001TH7GUU    4.782216\n",
      "33  A2PREU4LOFQRB1  B001TH7T2U    4.775793\n",
      "34  A2PREU4LOFQRB1  B00IVFDZBC    4.774087\n",
      "35  A2BLFCOPSMBOZ9  B0052SCU8U    4.574062\n",
      "36  A2BLFCOPSMBOZ9  B0019EHU8G    4.545132\n",
      "37  A2BLFCOPSMBOZ9  B001TH7T2U    4.535659\n",
      "38  A2BLFCOPSMBOZ9  B001TH7GUU    4.532675\n",
      "39  A2BLFCOPSMBOZ9  B000QUUFRW    4.507469\n",
      "40  A23GFTVIETX7DS  B0052SCU8U    4.798144\n",
      "41  A23GFTVIETX7DS  B001TH7T2U    4.764966\n",
      "42  A23GFTVIETX7DS  B0019EHU8G    4.759347\n",
      "43  A23GFTVIETX7DS  B001TH7GUU    4.753559\n",
      "44  A23GFTVIETX7DS  B000BQ7GW8    4.728911\n",
      "45  A1Q5P5ML3176C0  B0052SCU8U    4.819127\n",
      "46  A1Q5P5ML3176C0  B001TH7T2U    4.816278\n",
      "47  A1Q5P5ML3176C0  B0019EHU8G    4.805567\n",
      "48  A1Q5P5ML3176C0  B000M2TAN4    4.803658\n",
      "49  A1Q5P5ML3176C0  B001TH7GUU    4.778906\n",
      "50  A16RI68PS6T5CA  B0052SCU8U    4.556968\n",
      "51  A16RI68PS6T5CA  B000BQ7GW8    4.521457\n",
      "52  A16RI68PS6T5CA  B001TH7T2U    4.504843\n",
      "53  A16RI68PS6T5CA  B001TH7GUU    4.498906\n",
      "54  A16RI68PS6T5CA  B0019EHU8G    4.492848\n"
     ]
    }
   ],
   "source": [
    "print(top_5_recos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Based on our observations below are the key points\n",
    "\n",
    "\n",
    "1) We biased our original dataset in two places, one at begining of all the models where we keep the users who gave equal to or  more than 50 ratings thus reducing the number of records from 7824481 to 125871 and the other at the begining of CF model being analysed using surprise package which is done to avoid memory error, there the number of records further reduced from 125871 to 27265.\n",
    "\n",
    "2) From popularity based model we see same set of items are recommended to all the users. Personalisation is not possible in popularity based model.\n",
    "\n",
    "3) From CF models we choose the Item based approach(IBCF) since the number of users are very large and we took following approach:-\n",
    "\n",
    "3.1) IBCF using matrix based factorisation method SVD - performed on 125871 records - RMSE = 0.00275 (best score)\n",
    "\n",
    "3.2) IBCF KNNWithMeans using surprise package without tuning parameters - performed on 27265 records - RMSE = 0.9599\n",
    "\n",
    "3.3) IBCF KNNWithMeans using surprise package with tuning parameters - performed on 27265 records - RMSE = 0.9220\n",
    "\n",
    "3.4) IBCF SVD using surprise package without tuning parameters - performed on 27265 records - RMSE = 1.3843\n",
    "\n",
    "3.5) IBCF SVD using surprise package with tuning parameters - performed on 27265 records - RMSE = 1.3843\n",
    "\n",
    "So biasing the dataset led to poor recommendation system for 3.2,3.3,3.4 and 3.5, hence we prefer the model in 3.1 giving good RMSE value done on 125871 records.\n",
    "\n",
    "In all the 5 CF models we get user based personalised recommendations. So personalisation is possible in collaborative filtering model. Hence CF model is a good choice over popularity based model when users are known"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
